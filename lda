@Test
void testConvertCsvToParquetAndUpload_Success() throws IOException {
    String sourceBucketName = "source-bucket";
    String sourceFileKey = "source.csv";
    String fileTobeProcessed = "gbi_party";
    String destinationBucketName = "destination-bucket";
    String destinationFileKey = "destination.parquet";

    // Mock the S3 client behavior for reading the CSV file
    ResponseInputStream<GetObjectResponse> responseInputStream = mock(ResponseInputStream.class);
    when(s3Client.getObject(any(GetObjectRequest.class))).thenReturn(responseInputStream);
    
    // Mocked CSV data, ensuring all fields are present
    List<String[]> csvData = Arrays.asList(
        new String[]{"header1", "header2", "EFF_DT", "ETL_TS"}, // Headers
        new String[]{"value1", "value2", "", ""}               // Data row, EFF_DT and ETL_TS are empty
    );

    // Spy on snapshotService and mock the readCsvFromS3 method to return the csvData
    doReturn(csvData).when(snapshotService).readCsvFromS3(anyString(), anyString());

    // Mock schema loading
    doReturn("{\"type\": \"record\", \"name\": \"test\", \"fields\": [{\"name\": \"header1\", \"type\": \"string\"}, {\"name\": \"header2\", \"type\": \"string\"}, {\"name\": \"EFF_DT\", \"type\": \"string\"}, {\"name\": \"ETL_TS\", \"type\": \"string\"}]}").when(snapshotService).loadJsonSchema(anyString());

    // Mock S3 putObject behavior
    when(s3Client.putObject(any(PutObjectRequest.class), any(RequestBody.class))).thenReturn(null);

    // No exception should be thrown
    assertDoesNotThrow(() -> snapshotService.convertCsvToParquetAndUpload(sourceBucketName, sourceFileKey, fileTobeProcessed, destinationBucketName, destinationFileKey));

    // Verify S3 interactions
    verify(s3Client).getObject(any(GetObjectRequest.class));
    verify(s3Client).putObject(any(PutObjectRequest.class), any(RequestBody.class));
}
